{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This script is a machine learning application for training a Support Vector Machine (SVM) classifier to distinguish between positive and negative image samples. It performs data preprocessing, feature extraction, hyperparameter tuning, classifier training, evaluation, and model saving. The goal is to create a more robust classifier by augmenting the dataset, using HOG features, and incorporating hard negative mining. The script consists of several steps and components, which I'll explain in detail*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* 1. [Import Libraries](#1)\n",
    "   \n",
    "* 2. [Define Image Directories](#2)\n",
    "\n",
    "* 3. [Load Images](#3)\n",
    "   \n",
    "* 4. [Patch Extraction and Augmentation](#4)\n",
    "  \n",
    "* 5. [Simulated Distance Variation (Augmentation)](#5)\n",
    "\n",
    "* 6. [Mirror Augmentation](#6)\n",
    "\n",
    "* 7. [Creating the Dataset and Labels](#7)\n",
    "\n",
    "* 8. [Feature Extraction (HOG)](#8)\n",
    "\n",
    "* 9. [Train-Test Split](#9)\n",
    "\n",
    "* 10. [Hyperparameter Tuning](#10)\n",
    "\n",
    "* 11. [Training the SVM Classifier](#11)\n",
    "\n",
    "* 12. [Evaluation and Printing Results](#12)\n",
    "\n",
    "* 13. [Hard Negative Mining](#13)\n",
    "\n",
    "* 14. [Updating Training Data with Hard Negatives](#14)\n",
    "\n",
    "* 15. [Retraining SVM with Hard Negatives](#15)\n",
    "\n",
    "* 16. [Saving the Trained Model](#16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"> </a>\n",
    "#### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script starts with importing the necessary libraries, such as functions from libraries like OpenCV for image processing, scikit-learn for machine learning, and  functions from a custom utility module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"> </a>\n",
    "#### 2. Define Image Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* positive_images_folder: Path to the directory containing positive image samples.\n",
    "* negative_images_folder: Path to the directory containing negative image samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"> </a>\n",
    "#### 3. Load Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load_positive_images() and load_negative_images(): Functions that load the positive and negative image samples from the specified folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images_folder = \"positive_images\"\n",
    "negative_images_folder = \"negative_images\"\n",
    "\n",
    "positive_images=load_positive_images(positive_images_folder)\n",
    "negative_images=load_negative_images(negative_images_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"> </a>\n",
    "#### 4. Patch Extraction and Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* num_patches_per_image: Number of patches to extract from each negative image.\n",
    "* patch_size: Size of the patches to extract.\n",
    "* augmented_negative_images: A list to hold augmented negative image patches.\n",
    "* Loop through each negative image:\n",
    "  * Extract random patches from the image using the extract_random_patches() function.\n",
    "  * Extend the augmented_negative_images list with the extracted patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches_per_image = 3\n",
    "patch_size = (64, 64)\n",
    "augmented_negative_images=[]\n",
    "for image in negative_images:\n",
    "    patches = extract_random_patches(image, num_patches_per_image, patch_size)\n",
    "    augmented_negative_images.extend(patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"> </a>\n",
    "#### 5. Simulated Distance Variation (Augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* scale_factors: List of scaling factors for simulating distance variation.\n",
    "* augmented_positive_images: A list to hold augmented positive images.\n",
    "* Loop through each positive image:\n",
    "  * Simulate distance variations by applying scaling to the image using the simulate_distance_variation() function.\n",
    "  * Extend the augmented_positive_images list with the simulated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factors = [1.0]\n",
    "augmented_positive_images = []\n",
    "for image in positive_images:\n",
    "    simulated_images = simulate_distance_variation(image, scale_factors)\n",
    "    augmented_positive_images.extend(simulated_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"> </a>\n",
    "#### 6. Mirror Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mirror_augmented_positive_images: Create mirror images of the augmented positive images.\n",
    "* Extend the mirror_augmented_positive_images list with the mirror images and the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirror_augmented_positive_images = add_mirror_images(augmented_positive_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"> </a>\n",
    "#### 7. Creating the Dataset and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dataset: Combined list of augmented positive images and augmented negative image patches.\n",
    "* labels: List of labels corresponding to the dataset, where 1 represents positive samples and 0 represents negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mirror_augmented_positive_images + augmented_negative_images\n",
    "labels = [1] * len(mirror_augmented_positive_images) + [0] * len(augmented_negative_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"> </a>\n",
    "#### 8. Feature Extraction (HOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOG (Histogram of Oriented Gradients) feature extraction is a technique used in computer vision and image processing. It involves analyzing the distribution of gradient orientations in an image to capture its local texture and shape information.\n",
    "* features_list: A list to store the HOG feature vectors for each image in the dataset.\n",
    "* Loop through each image in the dataset:\n",
    "  * Extract HOG features using the get_hog_features() function. This function also implements within it a second function for image resizing (see utils.py). Its deafult arguments are: \n",
    "    * _resize_width=64_\n",
    "    * _resize_height=64_ \n",
    "    * _orient = 9_ \n",
    "    * _pix_per_cell = 8_\n",
    "    * _cell_per_block = 2_\n",
    "  * Append the features to the features_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for image in dataset:\n",
    "    features = get_hog_features(image)\n",
    "    features_list.append(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"> </a>\n",
    "#### 9. Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataset and labels into training and testing sets using train_test_split()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"> </a>\n",
    "#### 10. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* param_grid: A dictionary containing the hyperparameters to be tuned (C and loss) for the SVM classifier.\n",
    "* Create an instance of LinearSVC and perform hyperparameter tuning using GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\"> </a>\n",
    "#### 11. Training the SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a new LinearSVC classifier with the best hyperparameters obtained from the grid search.\n",
    "* Fit the classifier using the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"> </a>\n",
    "#### 12. Evaluation and Printing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make predictions on the test data using the trained classifier.\n",
    "* Print a classification report that includes precision, recall, F1-score, and support for both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1811\n",
      "           1       1.00      1.00      1.00     28001\n",
      "\n",
      "    accuracy                           1.00     29812\n",
      "   macro avg       1.00      1.00      1.00     29812\n",
      "weighted avg       1.00      1.00      1.00     29812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_list, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0],           \n",
    "    'loss': ['squared_hinge'],  \n",
    "}\n",
    "\n",
    "svm = LinearSVC(dual=False, random_state=42)  \n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "svm = LinearSVC(dual=False, random_state=42, C=best_params['C'], loss=best_params['loss'])\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"13\"> </a>\n",
    "#### 13. Hard Negative Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* negative_images_augmented: Take a subset of the original negative images for hard negative mining.\n",
    "* stepSize: The step size for sliding a window over the images for hard negative mining.\n",
    "* Perform hard negative mining using the hard_negative_mining() function to identify challenging negative samples. This function also implements within it a sliding window function, the portions are then submitted to the get_hog_features function and made a prediction with the trained classifier; in case the prediction == 1 (false positives), appended to an empty list (see utils.py). its deafult arguments are: windowSize = (64, 64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_images_augmented = negative_images[:500] \n",
    "stepSize = 20\n",
    "\n",
    "hard_negatives = hard_negative_mining(svm, negative_images_augmented, stepSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"14\"> </a>\n",
    "#### 14. Updating Training Data with Hard Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Append the HOG features of the hard negative samples to the training features.\n",
    "* Update the labels accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hard_negatives = np.vstack([X_train, [get_hog_features(img) for img in hard_negatives]])\n",
    "y_train_hard_negatives = np.concatenate([y_train, np.zeros(len(hard_negatives))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"15\"> </a>\n",
    "#### 15. Retraining SVM with Hard Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a new LinearSVC classifier instance and train it using the updated training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, dual=False, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_with_hard_negatives = LinearSVC(dual=False, random_state=42, C=best_params['C'], loss=best_params['loss'])\n",
    "svm_with_hard_negatives.fit(X_train_hard_negatives, y_train_hard_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"16\"> </a>\n",
    "#### 16. Saving the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save the final trained SVM classifier (with hard negatives) using the joblib.dump() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_with_hard_negatives']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_with_hard_negatives, 'svm_with_hard_negatives')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
